{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "import seaborn as sns    \n",
    "from surprise.prediction_algorithms.baseline_only import BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings = pd.read_csv(\"train_data.csv\")\n",
    "test_ratings = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_minimum_rating', 0.5)\n",
      "('train_maximum_rating', 5.0)\n",
      "('test_minimum_rating', 0.5)\n",
      "('test_maximum_rating', 5.0)\n"
     ]
    }
   ],
   "source": [
    "print('train_minimum_rating',min(train_ratings['rating']))\n",
    "print('train_maximum_rating',max(train_ratings['rating']))\n",
    "print('test_minimum_rating',min(train_ratings['rating']))\n",
    "print('test_maximum_rating',max(train_ratings['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coverage(threshold1, threshold2,prediction):\n",
    "    start_time=time.time()\n",
    "    predictions = pd.DataFrame(prediction)\n",
    "    pred = predictions.groupby('uid')\n",
    "    df1= pred.apply(lambda x: x.sort_values(by=[\"est\"],ascending=False))\n",
    "    df2=df1.reset_index(drop=True)\n",
    "    df3 = df2.groupby('uid').head(10)\n",
    "\n",
    "    s1=df3[df3['r_ui'] > threshold1].groupby('uid')['r_ui'].count().reset_index()\n",
    "    s2 = df3.pivot_table(index=['uid'],aggfunc='size').reset_index()\n",
    "    s2.columns = ['uid','counts']\n",
    "\n",
    "    df=pd.merge(s1, s2, on='uid')\n",
    "\n",
    "    # #number of high true rating(larger than 4) devided by top N predictions\n",
    "    df['rate']=df['r_ui']/df['counts']\n",
    "\n",
    "    user_coverage=float(sum(df['rate']> threshold2))/df3['uid'].nunique()\n",
    "\n",
    "    item=df3.groupby('iid').apply(lambda x: x.sort_values(by=[\"est\"],ascending=False)).reset_index(drop=True)\n",
    "\n",
    "    s=item[item['r_ui'] > threshold1].groupby('iid')['r_ui'].count().reset_index()\n",
    "    ss = item.pivot_table(index=['iid'],aggfunc='size').reset_index()\n",
    "    ss.columns = ['iid','counts']\n",
    "    dff=pd.merge(s, ss, on='iid')\n",
    "    dff['rate']=dff['r_ui']/dff['counts']\n",
    "    item_coverage=float(sum(dff['rate']> threshold2))/df3['iid'].nunique()\n",
    "\n",
    "    catalog_coverage = float(df3['iid'].nunique())/predictions['iid'].nunique()\n",
    "    end_time=time.time()\n",
    "    duration=end_time-start_time\n",
    "    return user_coverage, item_coverage, catalog_coverage,duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "ratings = Dataset.load_from_df(train_ratings, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_ratings = ratings.raw_ratings\n",
    "random.seed(42)\n",
    "shuffle(raw_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings.raw_ratings = raw_ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copy_ratings=ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_rating = Dataset.load_from_df(test_ratings, reader)\n",
    "test_raw_rating=test_rating.raw_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SGD\n",
      "Estimating biases using sgd...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x10978bbd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Using SGD')\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'learning_rate': .00005,\n",
    "               }\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "algo.fit(ratings.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ratings.construct_testset(test_raw_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result = algo.test(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE and MAE on test set using baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9691\n",
      "MAE:  0.7611\n"
     ]
    }
   ],
   "source": [
    "test_rmse = accuracy.rmse(test_result)\n",
    "test_mae = accuracy.mae(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user-coverage,item-coverage, catalog, running time on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17297840281265695,\n",
       " 0.11483253588516747,\n",
       " 0.8365577051367579,\n",
       " 21.256478786468506)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage(4.0, 0.5,test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
