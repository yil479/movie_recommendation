{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "from pyspark import SparkConf, SparkContext\nimport pyspark\nimport sys\nfrom collections import defaultdict\nimport pandas as pd\nimport numpy as np\nfrom itertools import combinations, permutations\n#configure spark\nDATA_PATH = \"gs://zw2624-bucket/input/subsample_data_3.csv\"\nK = 10"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "conf = SparkConf()\nsc = SparkContext.getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "def parseVector(line):\n    line = line.split(\",\")\n    return line[0],(line[1],line[2])\n\ndef reduceMean(line):\n    uid = line[0]\n    mean = sum([p[1] for p in line[1]]) / len(line[1])\n    return uid, [(p[0], p[1] - mean) for p in line[1]]\n\ndef getItemPairs(user_id,items_with_rating):\n    for item1,item2 in permutations(items_with_rating, 2):\n        yield (item1[0],item2[0]),(item1[1],item2[1]) \n    return\n    \ndef adjustedCosine(p):\n    item_pair = p[0] \n    pair_rating = p[1]\n    up = sum(s[0]*s[1] for s in pair_rating)\n    down = np.sqrt(sum(s[0]**2 for s in pair_rating) * sum(s[1]**2 for s in pair_rating))\n    return item_pair, up / down\n\ndef keyOnFirst(p):\n    item_pair,item_sim_data = p[0], p[1]\n    (item1_id,item2_id) = item_pair\n    return item1_id, (item2_id,item_sim_data)\n\ndef KNN(item, k):\n    item_id = item[0]\n    item_data = item[1]\n    item_data.sort(key = lambda x: x[1], reverse=True) \n    return item_id, item_data[:k]\n"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "data = sc.textFile(DATA_PATH).map(parseVector) \\\n                             .filter(lambda line: line[1][1] != 'rating') \\\n                             .map(lambda x: (x[0],(x[1][0],float(x[1][1]))))"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "'''\nuser_id, [(item1,item1_rating-mean), (item2, item2_rating-mean), ...]\n'''\nuser_item_pairs = data.groupByKey().map(reduceMean).cache()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "'''\n(item1,item2), [(item1_rating,item2_rating), (item1_rating,item2_rating), ...]\n'''\npairwise_items = user_item_pairs.flatMap(lambda p: getItemPairs(p[0],p[1])) \\\n                                .groupByKey().cache()\npairwise_items.take(3)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "'''\n(item1,item2), adjusted_cosine_similarity\n'''\nitem_sims = pairwise_items.map(adjustedCosine).cache()\nitem_sims.take(3)"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "item_neighbors = item_sims.map(keyOnFirst) \\\n                          .groupByKey().map(lambda x : (x[0], list(x[1]))) \\\n                          .map(lambda x: KNN(x, K)).cache()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.9"}}, "nbformat": 4, "nbformat_minor": 2}